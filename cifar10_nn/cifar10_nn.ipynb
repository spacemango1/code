{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "87f17185",
   "metadata": {},
   "source": [
    "*Adapted from: https://keras.io/examples/vision/mnist_convnet/*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "646b60e0",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee9c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow.keras as keras\n",
    "from tensorflow.keras import layers\n",
    "print(keras.__version__)\n",
    "keras.backend.backend()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4223bf8",
   "metadata": {},
   "source": [
    "# Load the data\n",
    "\n",
    "This time we are loading the cifar-10 dataset. It is structure in the same was as the MNIST dataset, ie split into training and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d439f4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the data, split between train and test sets\n",
    "(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f89f194e",
   "metadata": {},
   "source": [
    "# Display the data\n",
    "\n",
    "The cifar-10 dataset are all low resolution images of everyday objects and you can have a preview of what some looks like below. There are a total of 10 classes. Notably these are all colour images and not black and white images, it complicates things a little when it comes to working with our neural network but not by very much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc00141",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.clf()\n",
    "for i in range(9):\n",
    "    ax = plt.subplot(3, 3, i + 1)\n",
    "    plt.imshow(x_train[i])\n",
    "    plt.title(y_train[i][0])\n",
    "    plt.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aea072f2",
   "metadata": {},
   "source": [
    "# Prepare the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74ae83ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scale images to the [0, 1] range\n",
    "x_train = x_train.astype(\"float32\") / 255\n",
    "x_test = x_test.astype(\"float32\") / 255\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "# Model / data parameters\n",
    "num_classes = 10\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43e5c317",
   "metadata": {},
   "source": [
    "# Build the model\n",
    "\n",
    "The Keras flatten layer nicely flattens the colour images data for us so we don't have to worry about processing it ourselves. Overall same structure as what we had with the MNIST network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d00274",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = keras.Sequential(\n",
    "    [\n",
    "        layers.InputLayer(input_shape=input_shape),\n",
    "        layers.Flatten(),\n",
    "        layers.Dense(48, activation=\"relu\"),\n",
    "        layers.Dense(64, activation=\"relu\"),\n",
    "        layers.Dense(48, activation=\"relu\"),\n",
    "        layers.Dense(num_classes, activation=\"softmax\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d12754e9",
   "metadata": {},
   "source": [
    "# Train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9276d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128\n",
    "epochs = 15\n",
    "\n",
    "model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n",
    "\n",
    "model.fit(x_train, y_train, batch_size=batch_size, epochs=epochs, validation_split=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3c621ee",
   "metadata": {},
   "source": [
    "# Evaluate the trained model\n",
    "\n",
    "The expected test accuracy here is about 47%, which is not good enough (but better than random guesses which will have an accuracy of only 10%!)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba2b4f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "score = model.evaluate(x_test, y_test, verbose=0)\n",
    "print(\"Test loss:\", score[0])\n",
    "print(\"Test accuracy:\", score[1])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
